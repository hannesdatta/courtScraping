{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f802260e",
      "metadata": {
        "id": "f802260e"
      },
      "outputs": [],
      "source": [
        "# only run if you have installed Selenium on your local computer!\n",
        "from bs4 import BeautifulSoup # this installs the BeautifulSoup package\n",
        "\n",
        "import requests # we will need this to get the URL\n",
        "\n",
        "# the following packages are for creating the dataframe for the results\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "\n",
        "# if above solutions did not work or you ran into problems with the PATH variable, try the following: driver = selenium.webdriver.Chrome(chrome_path = <PATH_TO_FILE>)\n",
        "# tip: if your Chromedriver chrashes or does not work as expected throughout the exercises, run this cell again to create a new instance of the chromedriver"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First, we will start scraping www.ttlawcourts.org. We will go from one keyword to another"
      ],
      "metadata": {
        "id": "EvuP941rIeMG"
      },
      "id": "EvuP941rIeMG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50328f88",
      "metadata": {
        "id": "50328f88",
        "outputId": "5dae0bba-18d1-4989-baa8-53676dfdf819",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ]
        }
      ],
      "source": [
        "## scraping the keyword : referral \n",
        "\n",
        "# copy and paste the URL of the page of the search result here: \n",
        "url = \"https://www.ttlawcourts.org/index.php/advance-search?searchword=referral&ordering=newest&searchphrase=all&limit=0\"\n",
        "\n",
        "# make a get request to the URL\n",
        "request_object = requests.get(url, verify = False)\n",
        "\n",
        "# return the source code from the request object\n",
        "source_code = request_object.text\n",
        "\n",
        "soup = BeautifulSoup(source_code, \"html.parser\")\n",
        "\n",
        "# Since we are interested in the title of our results, our \"scraper\" gets the titles\n",
        "# the class name of the titles are \"result-title\". You can see this by right \n",
        "# clicking on the website, then click \"Inspect\". Be careful ! : the class name \n",
        "# changes from website to website\n",
        "\n",
        "referral_data = soup.find_all(class_=\"result-title\")\n",
        "\n",
        "# this section gets the titles of the search result and saves them in a list\n",
        "referral_list = []\n",
        "for title in referral_data:\n",
        "    title = title.text\n",
        "    \n",
        "    referral_list.append(title)\n",
        "\n",
        "referral_list\n",
        "\n",
        "# converting the list of the titles into a dataframe and saving that dataframe \n",
        "# as an Excel file. The file should be saved where your jupyter notebook is located.\n",
        "# However, on Google Colloborator, you can see it under the file symbol on the left. \n",
        "df = pd.DataFrame(list(zip(referral_list)), columns=[\"Referral\"])\n",
        "df.to_excel('referral_ttlaw.xlsx', index=False)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "354189f2",
      "metadata": {
        "id": "354189f2",
        "outputId": "e663e744-b4e4-4b22-a737-60d883dee563",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ]
        }
      ],
      "source": [
        "## scraping the keyword : referral jurisdiction\n",
        "\n",
        "del df \n",
        "\n",
        "# copy and paste the URL of the page of the search result here: \n",
        "url = \"https://www.ttlawcourts.org/index.php/advance-search?searchword=referral%20jurisdictio&searchphrase=all\"\n",
        "\n",
        "# make a get request to the URL\n",
        "request_object = requests.get(url, verify = False)\n",
        "\n",
        "# return the source code from the request object\n",
        "source_code = request_object.text\n",
        "\n",
        "soup = BeautifulSoup(source_code, \"html.parser\")\n",
        "\n",
        "# Since we are interested in the title of our results, our \"scraper\" gets the titles\n",
        "# the class name of the titles are \"result-title\". You can see this by right \n",
        "# clicking on the website, then click \"Inspect\". Be careful ! : the class name \n",
        "# changes from website to website\n",
        "\n",
        "refjuris_data = soup.find_all(class_=\"result-title\")\n",
        "\n",
        "# this section gets the titles of the search result and saves them in a list\n",
        "\n",
        "refjuris_list = []\n",
        "for title in refjuris_data:\n",
        "    title = title.text\n",
        "    \n",
        "    refjuris_list.append(title)\n",
        "    \n",
        "   \n",
        "refjuris_list\n",
        "\n",
        "# converting the list of the titles into a dataframe and saving that dataframe \n",
        "# as an Excel file. The file should be saved where your jupyter notebook is located.\n",
        "# However, on Google Colloborator, you can see it under the file symbol on the left.\n",
        "df = pd.DataFrame(list(zip(refjuris_list)), columns=[\"Referral Jurisdiction\"])\n",
        "df.to_excel('refjuris_ttlaw.xlsx', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94b35e2b",
      "metadata": {
        "id": "94b35e2b"
      },
      "outputs": [],
      "source": [
        "## scraping the keyword : Article 214 RTC\n",
        "\n",
        "# I got no results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4969e6e4",
      "metadata": {
        "id": "4969e6e4",
        "outputId": "1b17c285-600a-4da5-d565-c1940982cdb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ]
        }
      ],
      "source": [
        "## scraping the keyword : Caribbean Court of Justice\n",
        "\n",
        "#del df\n",
        "\n",
        "# copy and paste the URL of the page of the search result here: \n",
        "url = \"https://www.ttlawcourts.org/index.php/advance-search?searchword=Caribbean%20Court%20of%20J&searchphrase=all\"\n",
        "\n",
        "# make a get request to the URL\n",
        "request_object = requests.get(url, verify = False)\n",
        "\n",
        "# return the source code from the request object\n",
        "source_code = request_object.text\n",
        "\n",
        "soup = BeautifulSoup(source_code, \"html.parser\")\n",
        "\n",
        "# Since we are interested in the title of our results, our \"scraper\" gets the titles\n",
        "# the class name of the titles are \"result-title\". You can see this by right \n",
        "# clicking on the website, then click \"Inspect\". Be careful ! : the class name \n",
        "# changes from website to website\n",
        "caribbean_data = soup.find_all(class_=\"result-title\")\n",
        "\n",
        "# this section gets the titles of the search result and saves them in a list\n",
        "caribbean_list = []\n",
        "for title in caribbean_data:\n",
        "    title = title.text\n",
        "    \n",
        "    caribbean_list.append(title)\n",
        "    \n",
        "   \n",
        "caribbean_list\n",
        "\n",
        "# converting the list of the titles into a dataframe and saving that dataframe \n",
        "# as an Excel file. The file should be saved where your jupyter notebook is located.\n",
        "# However, on Google Colloborator, you can see it under the file symbol on the left.\n",
        "df = pd.DataFrame(list(zip(caribbean_list)), columns=[\"Caribbean Court of Justice\"])\n",
        "df.to_excel('caribbean_ttlaw.xlsx', index=False)\n",
        "\n",
        "# 20 / 50 results are saved in an Excel file \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## scraping the keyword : court of appeal \n",
        "\n",
        "# copy and paste the URL of the page of the search result here: \n",
        "url = \"https://www.ttlawcourts.org/index.php/advance-search?searchword=court%20of%20appeal&searchphrase=all\"\n",
        "\n",
        "# make a get request to the URL\n",
        "request_object = requests.get(url, verify = False)\n",
        "\n",
        "# return the source code from the request object\n",
        "source_code = request_object.text\n",
        "\n",
        "soup = BeautifulSoup(source_code, \"html.parser\")\n",
        "\n",
        "# Since we are interested in the title of our results, our \"scraper\" gets the titles\n",
        "# the class name of the titles are \"result-title\". You can see this by right \n",
        "# clicking on the website, then click \"Inspect\". Be careful ! : the class name \n",
        "# changes from website to website\n",
        "\n",
        "courtAp_data = soup.find_all(class_=\"result-title\")\n",
        "\n",
        "# this section gets the titles of the search result and saves them in a list\n",
        "courtAp_list = []\n",
        "for title in courtAp_data:\n",
        "    title = title.text\n",
        "    \n",
        "    courtAp_list.append(title)\n",
        "\n",
        "courtAp_list\n",
        "\n",
        "# converting the list of the titles into a dataframe and saving that dataframe \n",
        "# as an Excel file. The file should be saved where your jupyter notebook is located.\n",
        "# However, on Google Colloborator, you can see it under the file symbol on the left. \n",
        "df = pd.DataFrame(list(zip(courtAp_list)), columns=[\"Court of Appeal\"])\n",
        "df.to_excel('courtOfAppeal_ttlaw.xlsx', index=False)\n",
        "\n",
        "# the first 20 results could be scraped. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrSMouAgyOqs",
        "outputId": "9a4123af-a821-465d-d85a-0374c48af82b"
      },
      "id": "KrSMouAgyOqs",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2db33b2",
      "metadata": {
        "id": "e2db33b2",
        "outputId": "d7b05d0d-15f8-482f-a572-a0b0d92e2675",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ]
        }
      ],
      "source": [
        "## scraping the keyword : CCJ\n",
        "\n",
        "del df\n",
        "\n",
        "# copy and paste the URL of the page of the search result here: \n",
        "url = \"https://www.ttlawcourts.org/index.php/advance-search?searchword=CCJ&searchphrase=all\"\n",
        "\n",
        "# make a get request to the URL\n",
        "request_object = requests.get(url, verify = False)\n",
        "\n",
        "# return the source code from the request object\n",
        "source_code = request_object.text\n",
        "\n",
        "soup = BeautifulSoup(source_code, \"html.parser\")\n",
        "\n",
        "# Since we are interested in the title of our results, our \"scraper\" gets the titles\n",
        "# the class name of the titles are \"result-title\". You can see this by right \n",
        "# clicking on the website, then click \"Inspect\". Be careful ! : the class name \n",
        "# changes from website to website\n",
        "ccj_data = soup.find_all(class_=\"result-title\")\n",
        "\n",
        "# this section gets the titles of the search result and saves them in a list\n",
        "ccj_list = []\n",
        "for title in ccj_data:\n",
        "    title = title.text\n",
        "    \n",
        "    ccj_list.append(title)\n",
        "     \n",
        "ccj_list\n",
        "\n",
        "# converting the list of the titles into a dataframe and saving that dataframe \n",
        "# as an Excel file. The file should be saved where your jupyter notebook is located.\n",
        "# However, on Google Colloborator, you can see it under the file symbol on the left.\n",
        "df = pd.DataFrame(list(zip(ccj_list)), columns=[\"CCJ\"])\n",
        "df.to_excel('ccj_ttlaw.xlsx', index=False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First, we will start scraping http://rechtspraak.sr. We will go from one keyword to another"
      ],
      "metadata": {
        "id": "rbn_sJK_M7DW"
      },
      "id": "rbn_sJK_M7DW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## scraping the keyword : verwijzingsprocedure\n",
        "\n",
        "# there are no results\n",
        "\n"
      ],
      "metadata": {
        "id": "0U4Snd6xNBzx"
      },
      "id": "0U4Snd6xNBzx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## scraping the keyword : Herziene Verdrag van Chaguaramas\n",
        "\n",
        "# there are no results\n",
        "\n"
      ],
      "metadata": {
        "id": "rbwhgVgCNS8a"
      },
      "id": "rbwhgVgCNS8a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## scraping the keyword : verwijzing naar het Caribisch Hof van Justitie\n",
        "# there are no results"
      ],
      "metadata": {
        "id": "wYY7TkvMOci6"
      },
      "id": "wYY7TkvMOci6",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "scrapeCourts.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}